# ğŸ“ **AI & Data Science Portfolio**

<div align="center">

[![Portfolio](https://img.shields.io/badge/Portfolio-Live-blue?style=for-the-badge)](https://github.com/khachatryanDavid/AI-and-Data-Science-Portfolio)
[![Python](https://img.shields.io/badge/Python-3.8+-green?style=for-the-badge&logo=python)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0-red?style=for-the-badge&logo=pytorch)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)](LICENSE)

*A curated collection of research-grade projects in Machine Learning, Deep Learning, and Data Science*

[**View Projects**](#-repository-structure) â€¢ [**Core Skills**](#-core-skills-demonstrated) â€¢ [**About Me**](#-about-me) â€¢ [**Contact**](#-connect-with-me)

</div>

---

## ğŸ“– **Portfolio Overview**

Welcome to a **comprehensive journey** through Artificial Intelligence and Data Science. This portfolio represents hundreds of hours of rigorous study, experimentation, and implementation â€” transforming theoretical knowledge into practical, production-ready solutions.

Every project here reflects:
- **Deep theoretical understanding** backed by mathematical rigor
- **Clean, reproducible code** with extensive documentation
- **Real-world problem-solving** with measurable results
- **Research-level clarity** in explanations and visualizations

### ğŸ¯ **Mission Statement**

> *"To bridge the gap between theoretical AI and practical applications, building intelligent systems that don't just work â€” but are understood, explainable, and improvable."*

This portfolio is not just a collection of code â€” it's a **demonstration of analytical thinking**, **algorithmic reasoning**, and the ability to transform complex problems into elegant solutions.

---

## ğŸ—‚ï¸ **Repository Structure**

Each directory represents a complete, production-ready project with theoretical background, implementation, and comprehensive analysis.

### ğŸ“Š **Data Science & Analytics**
```
DS/
â”œâ”€â”€ Exploratory_Analysis/     â†’ Statistical analysis, hypothesis testing
â”œâ”€â”€ Feature_Engineering/      â†’ Advanced preprocessing techniques
â”œâ”€â”€ Visualization_Projects/   â†’ Interactive dashboards and insights
â”œâ”€â”€ Time_Series_Analysis/     â†’ Forecasting and trend detection
â””â”€â”€ A_B_Testing/             â†’ Experimental design and statistical inference
```

**Focus:** Turning raw data into actionable insights through statistical rigor and visual storytelling.

---

### ğŸ¤– **Classical Machine Learning**
```
Machine_Learning/
â”œâ”€â”€ Regression_Models/        â†’ Linear, Polynomial, Regularized Regression
â”œâ”€â”€ Classification/           â†’ Logistic Regression, SVM, Decision Trees
â”œâ”€â”€ Ensemble_Methods/         â†’ Random Forest, XGBoost, AdaBoost, Stacking
â”œâ”€â”€ Clustering/              â†’ K-Means, DBSCAN, Hierarchical, Gaussian Mixture
â”œâ”€â”€ Dimensionality_Reduction/ â†’ PCA, t-SNE, UMAP, Autoencoders
â””â”€â”€ Model_Selection/         â†’ Cross-validation, Hyperparameter tuning, Grid Search
```

**Focus:** Building robust ML pipelines from data preprocessing to model deployment.

---

### ğŸ”¥ **Deep Learning & Neural Networks**
```
PyTorch/
â””â”€â”€ neural-networks/
    â”œâ”€â”€ notebook1.ipynb      â†’ Baseline 2-layer NN | BCE Loss | 17 params
    â”œâ”€â”€ notebook2.ipynb      â†’ Scaled 3-layer NN | MSE Loss | 26 params | 71% improvement
    â””â”€â”€ notebook3.ipynb      â†’ Regularized NN | L2 Weight Decay | 43 params | Bias-variance analysis
```

**Key Experiments:**
- **Loss Function Comparison:** BCE vs MSE for binary classification
- **Scaling Strategy:** Impact of data size and model capacity
- **Regularization Effects:** L2 weight decay trade-offs

**Results:** Achieved 71% performance improvement through strategic architecture scaling and loss function optimization.

---

### ğŸ§® **Mathematical Foundations**
```
Mathematics_for_ML/
â”œâ”€â”€ Optimization/            â†’ Gradient Descent variants, Newton's Method, Conjugate Gradient
â”œâ”€â”€ Linear_Algebra/          â†’ Matrix decompositions, Eigenvalues, SVD
â”œâ”€â”€ Probability_Theory/      â†’ Distributions, Sampling, Monte Carlo methods
â”œâ”€â”€ Bayesian_Methods/        â†’ MLE, MAP, Bayesian Inference, MCMC
â””â”€â”€ Information_Theory/      â†’ Entropy, KL Divergence, Mutual Information
```

**Focus:** Understanding the mathematical machinery that powers AI algorithms.

---

### ğŸ¨ **Computer Vision** *(Coming Soon)*
```
Computer_Vision/
â”œâ”€â”€ Image_Classification/
â”œâ”€â”€ Object_Detection/
â”œâ”€â”€ Semantic_Segmentation/
â””â”€â”€ GANs_and_Diffusion/
```

---

### ğŸ’¬ **Natural Language Processing** *(Coming Soon)*
```
NLP/
â”œâ”€â”€ Text_Classification/
â”œâ”€â”€ Sentiment_Analysis/
â”œâ”€â”€ Transformers/
â””â”€â”€ LLM_Fine_Tuning/
```

---

## ğŸ“š **Core Skills Demonstrated**

### ğŸ”¬ **Data Science & Analytics**
| Skill | Tools | Proficiency |
|-------|-------|-------------|
| Data Wrangling | Pandas, NumPy | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80% |
| Statistical Analysis | SciPy, Statsmodels | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 75% |
| Data Visualization | Matplotlib, Seaborn, Plotly | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 85% |
| Feature Engineering | Domain expertise, Auto-FE | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 70% |
| A/B Testing | Hypothesis testing, Power analysis | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 65% |

### ğŸ¤– **Machine Learning**
| Algorithm Family | Implementation | Understanding |
|-----------------|----------------|---------------|
| Linear Models | Scikit-learn, Custom NumPy | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 85% |
| Tree-based Models | XGBoost, LightGBM, CatBoost | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80% |
| Ensemble Methods | Bagging, Boosting, Stacking | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 75% |
| Clustering | K-Means, DBSCAN, Hierarchical | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 70% |
| Dimensionality Reduction | PCA, t-SNE, UMAP | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 65% |

### ğŸ§  **Deep Learning**
| Concept | Framework | Mastery |
|---------|-----------|---------|
| Neural Network Architecture | PyTorch | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80% |
| Backpropagation & Optimization | Custom + PyTorch | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 75% |
| Loss Functions | BCE, MSE, Cross-Entropy | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 85% |
| Regularization | L2, Dropout, Early Stopping | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘ 75% |
| Training Diagnostics | Loss curves, Overfitting detection | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80% |

### ğŸ“ **Mathematical Foundations**
- **Calculus:** Derivatives, Gradients, Chain Rule, Optimization
- **Linear Algebra:** Matrix operations, Eigenvalues, SVD, Transformations
- **Probability:** Distributions, Bayes' Theorem, Maximum Likelihood
- **Statistics:** Hypothesis testing, Confidence intervals, Regression analysis
- **Optimization:** Gradient Descent, Newton's Method, Convex Optimization

---

## ğŸ› ï¸ **Technology Stack**

### **Languages**
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-4479A1?style=for-the-badge&logo=postgresql&logoColor=white)

### **Deep Learning**
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)

### **Machine Learning**
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-F7931E?style=for-the-badge&logo=scikitlearn&logoColor=white)
![XGBoost](https://img.shields.io/badge/XGBoost-337AB7?style=for-the-badge)

### **Data Science**
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Matplotlib](https://img.shields.io/badge/Matplotlib-11557c?style=for-the-badge)
![Seaborn](https://img.shields.io/badge/Seaborn-3776AB?style=for-the-badge)

### **Development Tools**
![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white)
![VS Code](https://img.shields.io/badge/VS_Code-007ACC?style=for-the-badge&logo=visualstudiocode&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)

---

## ğŸ¯ **Project Highlights**

### ğŸ† **Featured Project: Neural Network Training Dynamics**

**Problem:** Understanding how different loss functions and regularization techniques affect model performance and generalization.

**Approach:**
1. Built 3 progressively complex neural networks (17 â†’ 26 â†’ 43 parameters)
2. Compared BCE vs MSE loss functions
3. Tested L2 regularization impact on overfitting

**Results:**
- âœ… **71% improvement** switching from BCE to MSE with scaled architecture
- âœ… **Perfect train/val convergence** with L2 regularization (gap: 0.0005)
- âœ… **Zero overfitting** despite 2.5x parameter increase
- âš ï¸ **Key insight:** Regularization is not always beneficial â€” discovered that L2 hurt performance when overfitting wasn't present

**Impact:** Developed intuition for when to apply regularization vs when to scale model capacity.

---

### ğŸ“Š **Data Science Methodology**

Every project follows a rigorous, research-grade workflow:
```mermaid
graph LR
    A[Problem Definition] --> B[Literature Review]
    B --> C[Data Collection & Cleaning]
    C --> D[Exploratory Analysis]
    D --> E[Feature Engineering]
    E --> F[Model Development]
    F --> G[Hyperparameter Tuning]
    G --> H[Evaluation & Validation]
    H --> I[Interpretation & Insights]
    I --> J[Documentation & Deployment]
```

**Quality Standards:**
- âœ… Reproducible code with fixed random seeds
- âœ… Comprehensive error handling and data validation
- âœ… Extensive inline documentation and markdown explanations
- âœ… Rigorous cross-validation and test set evaluation
- âœ… Visual diagnostics for every critical decision
- âœ… Clear interpretation of results with limitations discussed

---

## ğŸ§  **Philosophy & Approach**

### **Core Principles**

1. **Understanding over Implementation**
   > *"I don't just import libraries â€” I understand what happens when I call `.fit()`"*

2. **Mathematics as Foundation**
   > *"Every algorithm is backed by mathematical intuition. No black boxes."*

3. **Reproducibility & Transparency**
   > *"Every result can be verified. Every decision is documented."*

4. **Failure is Data**
   > *"Failed experiments teach as much as successful ones. All results are valuable."*

5. **Real-World Focus**
   > *"Toy datasets are for learning. Real problems are for proving mastery."*

---

## ğŸ“ˆ **Learning Journey**

### **Completed Milestones**
- [x] Master NumPy fundamentals and vectorized operations
- [x] Build neural networks from scratch (no frameworks)
- [x] Implement backpropagation manually
- [x] Understand loss functions deeply (BCE vs MSE comparison)
- [x] Apply regularization techniques (L2, Dropout)
- [x] Diagnose overfitting through loss curve analysis
- [x] Scale models strategically (data + capacity)

### **Current Focus (November 2025)**
- [ ] Convolutional Neural Networks (CNNs)
- [ ] Recurrent architectures (RNNs, LSTMs, GRUs)
- [ ] Attention mechanisms and Transformers
- [ ] Transfer learning and fine-tuning
- [ ] Generative models (VAEs, GANs)

### **Future Goals (2026)**
- [ ] Large Language Models (LLMs)
- [ ] Reinforcement Learning
- [ ] MLOps and model deployment
- [ ] Research paper implementations
- [ ] Open-source contributions

---

## ğŸ‘¤ **About Me**

<div align="center">
<img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&weight=600&size=24&pause=1000&color=2E9EF7&center=true&vCenter=true&width=600&lines=AI+%26+Data+Science+Junior;Future+ML+Researcher;Problem+Solver+%7C+Critical+Thinker" alt="Typing SVG" />
</div>

**David Khachatryan**  
*Junior Machine Learning Engineer | AI Researcher in Training*

### **Academic Pursuits**
- ğŸ“ Currently studying: **Machine Learning, Data Science, Calculus, Probability Theory, Statistics**
- ğŸ¯ Goal: Admission to **MIT, Stanford, or Harvard** for AI/ML research
- ğŸ”¬ Research interests: **Optimization algorithms, Neural network interpretability, Mathematical foundations of AI**

### **What Drives Me**
I believe that true mastery comes from understanding **why** algorithms work, not just **how** to use them. Every line of code in this portfolio is backed by mathematical reasoning and experimental validation.

My approach:
- ğŸ“– **Read the papers** that introduced the algorithms
- âœï¸ **Implement from scratch** before using libraries
- ğŸ§ª **Experiment rigorously** to build intuition
- ğŸ“Š **Document thoroughly** for future reference
- ğŸ¤ **Share knowledge** to help others learn

### **Beyond Code**
- ğŸŒŸ Passionate about **Physics** and its connection to AI
- ğŸ§© Love solving complex problems that require creative thinking
- ğŸ“ Committed to **educational technology** and making AI accessible
- ğŸŒ Aspiring to contribute to **AI research** that benefits humanity

---

## ğŸ“¬ **Connect With Me**

<div align="center">

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/david-khachatryan-65a14b376/)
[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/khachatryanDavid)

**Open to:** Research Collaborations | ML Internships | Academic Discussions | Open Source Contributions

</div>

---

## ğŸ“Š **Portfolio Statistics**

<div align="center">

| Metric | Count |
|--------|-------|
| **Total Projects** | 15+ |
| **Notebooks Completed** | 25+ |
| **Lines of Code** | 10,000+ |
| **Research Hours** | 500+ |
| **Topics Covered** | 30+ |
| **Models Trained** | 100+ |

</div>

---

## ğŸ† **Key Achievements**

- ğŸ¯ **71% performance improvement** through strategic loss function selection
- ğŸ”¬ **Zero overfitting** despite 2.5x model complexity increase
- ğŸ“ˆ **Perfect train/validation convergence** (0.0005 gap) using L2 regularization
- ğŸ§ª **10+ rigorous experiments** comparing algorithms and techniques
- ğŸ“ **Research-grade documentation** across all projects
- ğŸ“ **Self-taught** PyTorch, NumPy, and ML mathematics

---

## ğŸ“„ **License**

This portfolio is licensed under the **MIT License** - feel free to use the code for learning purposes with proper attribution.

---

## ğŸŒŸ **Acknowledgments**

This journey wouldn't be possible without:
- The **open-source ML community** for incredible resources
- **Stanford CS229**, **fast.ai**, and **3Blue1Brown** for educational content
- **PyTorch documentation** for clear, comprehensive guides
- Every researcher who published their work openly

---

## ğŸ“… **Portfolio Timeline**

<div align="center">

| Period | Milestone | Focus Area |
|--------|-----------|------------|
| **October 2025** | ğŸ¬ Portfolio Initiated | Machine Learning Foundations |
| **November 2025** | ğŸ”¥ Deep Learning Era | Neural Networks with PyTorch |

</div>

---

**ğŸ¯ Not just applying algorithms â€” understanding why they work.**

---

**ğŸš€ Built with passion, powered by curiosity, driven by the pursuit of knowledge.**

---

ğŸ“ **Maintained by:** David Khachatryan  
ğŸ“… **Last Updated:** November 18, 2025  
â­ **Version:** 1.1.0

---

<div align="center">

*If this portfolio demonstrates the level of dedication and skill you're looking for, let's connect!*

[![Star this repo](https://img.shields.io/github/stars/khachatryanDavid/AI-and-Data-Science-Portfolio?style=social)](https://github.com/khachatryanDavid/AI-and-Data-Science-Portfolio)

</div>

---
# **Phrases**

<div align="center">

## **1. Machine Learning**

### ğŸ’¡ *"Machine learning is the science of getting computers to learn without being explicitly programmed."*
*â€” Andrew Ng*

---
## **2. Data Science**
<div align="center">

### ğŸ’¡ *"Without data, you're just another person with an opinion."*
*â€” W. Edwards Deming*

---
## **3. Neural Network**
<div align="center">

### ğŸ’¡ *"The brain is a three-pound mass you can hold in your hand that can conceive of a universe a hundred billion light-years across."*
*â€” Marian Diamond*
